# LMTSC-IOD

# Lightweight Multivariate Time-Series Classification for Indoor-Outdoor Detection

This repository contains the implementation and resources associated with the paper focusing on the accurate classification of indoor and outdoor environments using multivariate time series data.

## Abstract

In location-based services, accurately classifying indoor-outdoor detection (IOD) using context-aware sensors is a vital research topic. This paper presents a novel framework leveraging a lightweight, custom Bi-Parallel CNN-LSTM architecture and ensemble learning to significantly increase accuracy. Additionally, an adaptive feature scaling-based method is introduced for augmentation, resulting in improved model performance.

## Introduction

The accurate identification of transitions between indoor and outdoor environments is crucial for various applications. Traditional methods and existing deep learning models face challenges in capturing temporal dependencies and spatial patterns. This paper introduces an enhanced framework incorporating adaptive feature scaling, a novel CNN-LSTM architecture, and ensemble learning, surpassing limitations of prior approaches.

## Major Contributions

1. Introduction of a lightweight, custom Bi-Parallel CNN-LSTM architecture for distinguishing between indoor and outdoor settings.
2. Adaptive Feature Scaling (AFS) approach to dynamically adjust feature ranges, enhancing data representation.
3. Utilization of ensemble-based inference for increased prediction stability and performance.
4. Release of a novel dataset specifically designed for indoor-outdoor detection, promoting reproducibility and future research.

## Usage

The code and resources provided here implement the methodologies and techniques proposed in the paper. Follow the instructions in each directory to reproduce experiments and results.

## Citation

If you find this work helpful or use any part of the provided resources, please consider citing:

[Insert Paper Citation]

## License

This project is licensed under [Insert License]. See the LICENSE file for details.

---

For more details, methodology, and results, please refer to the full paper.

[Link to Paper PDF or DOI]

